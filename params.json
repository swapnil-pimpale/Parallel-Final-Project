{"name":"Parallel rendering of depth images for fast object localization","tagline":"","body":"### Summary\r\nWe are going to parallelize the rendering of multiple depth images for fast object localization on both GPU and multi-core CPU platforms and perform a detailed analysis of both systems' performance characteristics. This project idea is sponsored by Dr. Maxim Likhachev and Venkat Narayanan.\r\n\r\n### Background\r\nMany computer vision problems in robotics are constrained by the availability of camera pose and 3D object models. To this end, it would be beneficial to perform object detection and localization by ‘simulating’ all possible hypotheses (each hypothesis is a depth image), as opposed to a traditional feature-based discriminative approach. Dr. Likhachev’s current system detects and localizes known objects in a RGB-D image by searching through all possible hypotheses/depth images.\r\n\r\nThe current system in place is highly serial; the search algorithm that generates the set of all possible hypotheses/depth images is serial, the rendering of all the generated depth images is performed serially, and the actual algorithm to perform the rendering for a single depth image is also serial. In short, there are 3 layers of parallelization that can be implemented:\r\n* Layer 1: Parallelize rendering of a single depth image (or single hypothesis)\r\n* Layer 2: Parallelize rendering of multiple depth images (i.e, render multiple hypotheses in parallel)\r\n* Layer 3: Parallelize the search algorithm itself\r\n\r\nFor our project, we aim to focus on parallelizing the algorithm that renders a single hypothesis/depth image (Layer 1).\r\n\r\nInput to the system: A depth image of the scene from a sensor such as Kinect, 3D models of N objects, number of objects in the scene K (K<=N)\r\n\r\nOutput: Location and orientation of each of the K objects\r\n\r\nMethodology: We want to localize objects by generating a hypothesis (depth image) that best matches the input, according to some error metric. We will treat this problem as a graph search problem to smartly search through the space of all possible hypothesis. \r\n\r\n### The Challenge\r\nThe current algorithm for rendering a single depth image is a single-threaded serial implementation that is capable of running on a single CPU, with no known existing parallel implementation. The challenge lies in identifying data dependencies in the serial algorithm, and consequently using this information to determine how best to parallelize the algorithm, using the resources of a multi-core CPU and GPU. Comparing the performance of the parallel implementations on the CPU and the GPU will also shed light on the workloads’ amenability to a particular system architecture.\r\n\r\n### Resources\r\nWe plan to use the multi-core GHC CPUs and GHC GPUs for the project. The existing sequential algorithm for rendering a single depth image will be provided to us by Venkatraman Narayanan's (CMU PhD student), which we will study and then parallelize.\r\n\r\n### Goals and Deliverables\r\n**What we plan to achieve**\r\nWe plan to implement the Layer-1 phase on both GPU and multi-core CPU platforms and perform a detailed analysis of both systems' performance characteristics.\r\nWe plan to deliver the following:\r\n1. Documented source code for both the CPU and GPU-implementations of the parallelized rendering algorithm for a single depth image.\r\n2. Charts/Graphs depicting the speedups obtained by both implementations of the parallelized algorithm, relative to each other and relative to the serial algorithm.\r\nAnd possibly:\r\n3. A visual demo of the rendering of the depth image (using all 3 implementations)\r\n\r\n**What we hope to achieve**\r\nIf we find ourselves ahead of the schedule after the completion of the Layer-1 phase we will move on to implementing the Layer-2 and Layer-3 phases. We are targeting to complete the implementation and performance analysis for Layer-1 phase to start with. If time permits we would move on to implement Layer-2 and Layer-3 phases in that order.\r\n\r\n### Platform Choice\r\nFor the multi-core version of the algorithm we plan to use OpenMP and for the GPU version of the algorithm we plan to use CUDA.\r\n\r\nAs of this point, we do not know the exact hardware specifications of the Robot on which these algorithms will be run but since it is an embedded system we think that a shared-memory model like OpenMP is more appropriate for the CPU version.\r\n\r\nAs for the GPU version, CUDA is the most natural choice for programming.\r\n\r\n### Schedule\r\n* Week 1: Understand the existing code base and come up with an idea for parallel implementation.\r\n* Week 2: Build an early version of the test harness to measure correctness and speedup.\r\n* Week 3: Complete the implementation of the multi-core CPU version of the parallel algorithm.\r\n* Week 4: Complete the implementation of the GPU version of the parallel algorithm.\r\n* Week 5: Work on presentation, polishing the code, report, etc.\r\n\r\n### Authors and Contributors\r\nSwapnil Pimpale, Romit Kudtarkar","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}